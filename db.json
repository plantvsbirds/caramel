{
  "types": [
    "Object Detection",
    "image_processing",
    "Style Transfer",
    "text",
    "others"
  ],
  "model_download_url_prefix": "https://s3-us-west-2.amazonaws.com/coreml-models/",
  "models": [
    {
      "name": "MobileNet",
      "file": "MobileNet.mlmodel",
      "description": "The network from the paper \\'MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\\', trained on the ImageNet dataset.",
      "download_link": "https://github.com/hollance/MobileNet-CoreML/raw/master/MobileNet.mlmodel",
      "demo_link": "https://github.com/hollance/MobileNet-CoreML",
      "reference_link": "https://arxiv.org/abs/1704.04861",
      "type": "Object Detection",
      "license": "Unknown",
      "author": "Original paper: Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam. Caffe implementation: shicai",
      "output": [
        {
          "type": "Dictionary (String -> Double)",
          "name": "prob",
          "description": "Probability of each category"
        },
        {
          "type": "String",
          "name": "classLabel",
          "description": "Most likely image category"
        }
      ],
      "input": [
        {
          "type": "Image (Color 224 x 224)",
          "name": "data",
          "description": "Input image to be classified"
        }
      ],
      "size": "16.4 MB",
      "primary_output": "classLabel",
      "samples": [
        {
          "input": {
            "data": {
              "content": "ScreenShot2017-09-16at8.52.00PM.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "tiger cat",
              "type": "text"
            },
            "prob": {}
          }
        }
      ],
      "primary_input": "data"
    },
    {
      "name": "Resnet50",
      "file": "Resnet50.mlmodel",
      "description": "Detects the dominant objects present in an image from a set of 1000 categories such as trees, animals, food, vehicles, person etc. The top-5 error from the original publication is 7.8%.",
      "download_link": "https://github.com/ytakzk/CoreML-samples/blob/master/CoreML-samples/Resnet50.mlmodel",
      "demo_link": "https://github.com/ytakzk/CoreML-samples",
      "reference_link": "https://arxiv.org/abs/1512.03385",
      "type": "Object Detection",
      "license": "MIT License. More information available at https://github.com/fchollet/keras/blob/master/LICENSE",
      "author": "Original Paper: Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun. Keras Implementation: Fran\\303\\247ois Chollet",
      "output": [
        {
          "type": "Dictionary (String -> Double)",
          "name": "classLabelProbs",
          "description": "Probability of each category"
        },
        {
          "type": "String",
          "name": "classLabel",
          "description": "Most likely image category"
        }
      ],
      "input": [
        {
          "type": "Image (Color 224 x 224)",
          "name": "image",
          "description": "Input image of scene to be classified"
        }
      ],
      "size": "97.8 MB",
      "primary_output": "classLabel",
      "samples": [
        {
          "input": {
            "image": {
              "content": "ScreenShot2017-09-16at8.28.57PM.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "toy poodle",
              "type": "text"
            },
            "classLabelProbs": {}
          }
        }
      ],
      "primary_input": "image"
    },
    {
      "name": "AgeNet",
      "file": "AgeNet.mlmodel",
      "description": "Age Classification using Convolutional Neural Networks",
      "download_link": "https://s3-us-west-2.amazonaws.com/coreml-models/AgeNet.mlmodel",
      "demo_link": "https://github.com/cocoa-ai/FacesVisionDemo",
      "reference_link": "http://www.openu.ac.il/home/hassner/projects/cnn_agegender/",
      "type": "Object Detection",
      "license": "Unknown",
      "author": "Gil Levi and Tal Hassner",
      "output": [
        {
          "type": "Dictionary (String -> Double)",
          "name": "prob",
          "description": "The probabilities for each age, for the given input."
        },
        {
          "type": "String",
          "name": "classLabel",
          "description": "The most likely age, for the given input."
        }
      ],
      "input": [
        {
          "type": "Image (Color 227 x 227)",
          "name": "data",
          "description": "An image with a face."
        }
      ],
      "size": "43.5 MB",
      "primary_output": "classLabel",
      "samples": [
        {
          "input": {
            "data": {
              "content": "ScreenShot2017-09-154.59.42PM.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "60-100",
              "type": "text"
            },
            "prob": {}
          }
        },
        {
          "input": {
            "data": {
              "content": "ScreenShot20170915at4.54.34.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "25-32",
              "type": "text"
            },
            "prob": {}
          }
        }
      ],
      "primary_input": "data"
    },
    {
      "name": "GenderNet",
      "file": "GenderNet.mlmodel",
      "description": "Gender Classification using Convolutional Neural Networks",
      "download_link": "https://drive.google.com/file/d/0B1ghKa_MYL6mYkNsZHlyc2ZuaFk/view?usp=sharing",
      "demo_link": "https://github.com/cocoa-ai/FacesVisionDemo",
      "reference_link": "http://www.openu.ac.il/home/hassner/projects/cnn_agegender/",
      "type": "Object Detection",
      "license": "Unknown",
      "author": "Gil Levi and Tal Hassner",
      "output": [
        {
          "type": "Dictionary (String -> Double)",
          "name": "prob",
          "description": "The probabilities for each gender, for the given input."
        },
        {
          "type": "String",
          "name": "classLabel",
          "description": "The most likely gender, for the given input."
        }
      ],
      "input": [
        {
          "type": "Image (Color 227 x 227)",
          "name": "data",
          "description": "An image with a face."
        }
      ],
      "size": "43.5 MB",
      "primary_output": "classLabel",
      "samples": [
        {
          "input": {
            "data": {
              "content": "ScreenShot20170915at4.54.34.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "Male",
              "type": "text"
            },
            "prob": {}
          }
        },
        {
          "input": {
            "data": {
              "content": "ScreenShot2017-09-154.59.42PM.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "Female",
              "type": "text"
            },
            "prob": {}
          }
        }
      ],
      "primary_input": "data"
    },
    {
      "name": "MNIST",
      "file": "MNIST.mlmodel",
      "description": "Predicts a handwritten digit.",
      "download_link": "https://github.com/ph1ps/MNIST-CoreML/raw/master/MNISTPrediction/MNIST.mlmodel",
      "demo_link": "https://github.com/ph1ps/MNIST-CoreML",
      "reference_link": "http://yann.lecun.com/exdb/mnist/",
      "type": "Object Detection",
      "license": "MIT",
      "author": "Philipp Gabriel",
      "output": [
        {
          "type": "Dictionary (Int64 -> Double)",
          "name": "prediction",
          "description": "Array of predictions mapped to their indices"
        },
        {
          "type": "Int64",
          "name": "classLabel"
        }
      ],
      "input": [
        {
          "type": "Image (Gray scale 28 x 28)",
          "name": "image",
          "description": "Image to analyze"
        }
      ],
      "size": "2.3 MB",
      "primary_output": "classLabel",
      "samples": [
        {
          "input": {
            "image": {
              "content": "hand_writter_6.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "6",
              "type": "text"
            },
            "prediction": {}
          }
        },
        {
          "input": {
            "image": {
              "content": "hand_writter_8.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "8",
              "type": "text"
            },
            "prediction": {}
          }
        }
      ],
      "primary_input": "image"
    },
    {
      "name": "CNNEmotions",
      "file": "CNNEmotions.mlmodel",
      "description": "Emotion Recognition in the Wild via Convolutional Neural Networks and Mapped Binary Patterns",
      "download_link": "https://drive.google.com/file/d/0B1ghKa_MYL6mTlYtRGdXNFlpWDQ/view?usp=sharing",
      "demo_link": "https://github.com/cocoa-ai/FacesVisionDemo",
      "reference_link": "http://www.openu.ac.il/home/hassner/projects/cnn_emotions/",
      "type": "Object Detection",
      "license": "Unknown",
      "author": "Gil Levi and Tal Hassner",
      "output": [
        {
          "type": "Dictionary (String -> Double)",
          "name": "prob",
          "description": "The probabilities for each emotion, for the given input."
        },
        {
          "type": "String",
          "name": "classLabel",
          "description": "The most likely type of emotion, for the given input."
        }
      ],
      "input": [
        {
          "type": "Image (Color 224 x 224)",
          "name": "data",
          "description": "An image with a face."
        }
      ],
      "size": "475.0 MB",
      "primary_output": "classLabel",
      "samples": [
        {
          "input": {
            "data": {
              "content": "ScreenShot20170915at4.54.34.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "Fear",
              "type": "text"
            },
            "prob": {}
          }
        },
        {
          "input": {
            "data": {
              "content": "ScreenShot2017-09-154.59.42PM.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "Angry",
              "type": "text"
            },
            "prob": {}
          }
        }
      ],
      "primary_input": "data"
    },
    {
      "name": "VisualSentimentCNN",
      "file": "VisualSentimentCNN.mlmodel",
      "description": "Fine-tuning CNNs for Visual Sentiment Prediction",
      "download_link": "https://drive.google.com/open?id=0B1ghKa_MYL6mZ0dITW5uZlgyNTg",
      "demo_link": "https://github.com/cocoa-ai/SentimentVisionDemo",
      "reference_link": "http://www.sciencedirect.com/science/article/pii/S0262885617300355?via%3Dihub",
      "type": "Object Detection",
      "license": "MIT",
      "author": "Image Processing Group - BarcelonaTECH - UPC",
      "output": [
        {
          "type": "Dictionary (String -> Double)",
          "name": "prob",
          "description": "The probabilities for each sentiment, for the given input."
        },
        {
          "type": "String",
          "name": "classLabel",
          "description": "The most likely sentiment, for the given input."
        }
      ],
      "input": [
        {
          "type": "Image (Color 227 x 227)",
          "name": "data",
          "description": "An image."
        }
      ],
      "size": "217.0 MB",
      "primary_output": "prob",
      "samples": [
        {
          "input": {
            "data": {
              "content": "sentiment_screenshot.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "positive",
              "type": "text"
            },
            "prob": {
              "content": "{\n\tpositive: 90.9%\n\tnegative: 9.1%\n}",
              "type": "text"
            }
          }
        },
        {
          "input": {
            "data": {
              "content": "sentiment_screenshot2.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "negative",
              "type": "text"
            },
            "prob": {
              "content": "{\n\tpositive: 21.7%\n\tnegative: 78.3%\n}",
              "type": "text"
            }
          }
        }
      ],
      "primary_input": "data"
    },
    {
      "name": "Food101",
      "file": "Food101.mlmodel",
      "description": "This model takes a picture of a food and predicts its name",
      "download_link": "https://drive.google.com/open?id=0B5TjkH3njRqnVjBPZGRZbkNITjA",
      "demo_link": "https://github.com/ph1ps/Food101-CoreML",
      "reference_link": "http://visiir.lip6.fr/explore",
      "type": "Object Detection",
      "license": "Unknown",
      "author": "Philipp Gabriel",
      "output": [
        {
          "type": "Dictionary (String -> Double)",
          "name": "foodConfidence",
          "description": "Confidence and label of predicted food"
        },
        {
          "type": "String",
          "name": "classLabel",
          "description": "Label of predicted food"
        }
      ],
      "input": [
        {
          "type": "MultiArray (Double 3 x 299 x 299)",
          "name": "image",
          "description": "Image of a food"
        }
      ],
      "size": "83.3 MB",
      "primary_output": "classLabel",
      "samples": [
        {
          "input": {
            "image": {
              "content": "applepie-screen.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "apple pie",
              "type": "text"
            },
            "foodConfidence": {}
          }
        },
        {
          "input": {
            "image": {
              "content": "lobster-screen.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "lobster roll sandwish",
              "type": "text"
            },
            "foodConfidence": {}
          }
        },
        {
          "input": {
            "image": {
              "content": "ribs-screen.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "baby back ribs",
              "type": "text"
            },
            "foodConfidence": {}
          }
        },
        {
          "input": {
            "image": {
              "content": "steak-screen.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "steak",
              "type": "text"
            },
            "foodConfidence": {}
          }
        }
      ],
      "primary_input": "image"
    },
    {
      "name": "Oxford102",
      "file": "Oxford102.mlmodel",
      "description": "Classifying images in the Oxford 102 flower dataset with CNNs",
      "download_link": "https://drive.google.com/file/d/0B1ghKa_MYL6meDBHT2NaZGxkNzQ/view?usp=sharing",
      "demo_link": "https://github.com/cocoa-ai/FlowersVisionDemo",
      "reference_link": "http://jimgoo.com/flower-power/",
      "type": "Object Detection",
      "license": "Unknown",
      "author": "Jimmie Goode",
      "output": [
        {
          "type": "Dictionary (String -> Double)",
          "name": "prob",
          "description": "The probabilities for each flower type, for the given input."
        },
        {
          "type": "String",
          "name": "classLabel",
          "description": "The most likely type of flower, for the given input."
        }
      ],
      "input": [
        {
          "type": "Image (Color 227 x 227)",
          "name": "data",
          "description": "An image of a flower."
        }
      ],
      "size": "218.5 MB",
      "primary_output": "classLabel",
      "samples": [
        {
          "input": {
            "data": {
              "content": "rose_screen.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "rose",
              "type": "text"
            },
            "prob": {}
          }
        },
        {
          "input": {
            "data": {
              "content": "morning_glory_screen.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "morning_glory",
              "type": "text"
            },
            "prob": {}
          }
        }
      ],
      "primary_input": "data"
    },
    {
      "name": "FlickrStyle",
      "file": "FlickrStyle.mlmodel",
      "description": "Finetuning CaffeNet on Flickr Style",
      "download_link": "https://drive.google.com/file/d/0B1ghKa_MYL6meDBHT2NaZGxkNzQ/view?usp=sharing",
      "demo_link": "https://github.com/cocoa-ai/StylesVisionDemo",
      "reference_link": "http://sergeykarayev.com/files/1311.3715v3.pdf",
      "type": "Object Detection",
      "license": "Unknown",
      "author": "Sergey Karayev",
      "output": [
        {
          "type": "Dictionary (String -> Double)",
          "name": "prob",
          "description": "The probabilities for each style type, for the given input."
        },
        {
          "type": "String",
          "name": "classLabel",
          "description": "The most likely style of image, for the given input."
        }
      ],
      "input": [
        {
          "type": "Image (Color 227 x 227)",
          "name": "data",
          "description": "An image."
        }
      ],
      "size": "217.2 MB",
      "primary_output": "classLabel",
      "samples": [
        {
          "input": {
            "data": {
              "content": "vintage_image_sample.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "Vintage",
              "type": "text"
            },
            "prob": {}
          }
        },
        {
          "input": {
            "data": {
              "content": "ScreenShot2017-09-16at1.19.30AM.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "Pastel",
              "type": "text"
            },
            "prob": {}
          }
        }
      ],
      "primary_input": "data"
    },
    {
      "name": "RN1015k500",
      "file": "RN1015k500.mlmodel",
      "description": "Predict the location where a picture was taken.",
      "download_link": "https://s3.amazonaws.com/aws-bigdata-blog/artifacts/RN1015k500/RN1015k500.mlmodel",
      "demo_link": "https://github.com/awslabs/MXNet2CoreML_iOS_sample_app",
      "reference_link": "https://aws.amazon.com/blogs/ai/estimating-the-location-of-images-using-mxnet-and-multimedia-commons-dataset-on-aws-ec2",
      "type": "Object Detection",
      "input": [
        {
          "type": "Image (Color 224 x 224)",
          "name": "data"
        }
      ],
      "output": [
        {
          "type": "Dictionary (String -> Double)",
          "name": "softmax_output"
        },
        {
          "type": "String",
          "name": "classLabel"
        }
      ],
      "size": "284.4 MB",
      "primary_output": "softmax_output",
      "samples": [
        {
          "input": {
            "data": {
              "content": "ScreenShot2017-09-161.40.24AM.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {},
            "softmax_output": {
              "content": "ScreenShot2017-09-161.40.24AM_out.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "data": {
              "content": "ScreenShot2017-09-1611.41.59AM.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {},
            "softmax_output": {
              "content": "ScreenShot2017-09-1611.41.59AM_out.png",
              "type": "image"
            }
          }
        }
      ],
      "primary_input": "data"
    },
    {
      "name": "HED_so",
      "file": "HED_so.mlmodel",
      "description": "Holistically-Nested Edge Detection. Side outputs",
      "download_link": "https://github.com/s1ddok/HED-CoreML/blob/master/HED-CoreML/Models/HED_so.mlmodel",
      "demo_link": "https://github.com/s1ddok/HED-CoreML",
      "reference_link": "http://dl.acm.org/citation.cfm?id=2654889",
      "type": "image_processing",
      "license": "Unknown",
      "author": "Original paper: Xie, Saining and Tu, Zhuowen. Caffe implementation: Yangqing Jia. CoreML port: Andrey Volodin",
      "output": [
        {
          "type": "MultiArray (Double)",
          "name": "upscore-dsn1",
          "description": "Tensor that can be treated as single-channel texture where each pixel represents the probability of edge there. Should be normalized before usage (i.e. with sigmoid function)"
        },
        {
          "type": "MultiArray (Double)",
          "name": "upscore-dsn2",
          "description": "Tensor that can be treated as single-channel texture where each pixel represents the probability of edge there. Should be normalized before usage (i.e. with sigmoid function)"
        },
        {
          "type": "MultiArray (Double)",
          "name": "upscore-dsn3",
          "description": "Tensor that can be treated as single-channel texture where each pixel represents the probability of edge there. Should be normalized before usage (i.e. with sigmoid function)"
        },
        {
          "type": "MultiArray (Double)",
          "name": "upscore-dsn4",
          "description": "Tensor that can be treated as single-channel texture where each pixel represents the probability of edge there. Should be normalized before usage (i.e. with sigmoid function)"
        },
        {
          "type": "MultiArray (Double)",
          "name": "upscore-dsn5",
          "description": "Tensor that can be treated as single-channel texture where each pixel represents the probability of edge there. Should be normalized before usage (i.e. with sigmoid function)"
        }
      ],
      "input": [
        {
          "type": "Image (Color 500 x 500)",
          "name": "data",
          "description": "Input image to be edge-detected. Must be exactly 500x500 pixels."
        }
      ],
      "size": "56.1 MB",
      "primary_output": "upscore-dsn3",
      "samples": [
        {
          "input": {
            "data": {
              "content": "ScreenShot2017-09-16at9.58.01AM.png",
              "type": "image"
            }
          },
          "output": {
            "upscore-dsn5": {
              "content": "ScreenShot2017-09-16at9.58.01AM.dsn5.png",
              "type": "image"
            },
            "upscore-dsn4": {
              "content": "ScreenShot2017-09-16at9.58.01AM.dsn4.png",
              "type": "image"
            },
            "upscore-dsn1": {
              "content": "ScreenShot2017-09-16at9.58.01AM.dsn1.png",
              "type": "image"
            },
            "upscore-dsn3": {
              "content": "ScreenShot2017-09-16at9.58.01AM.dsn3.png",
              "type": "image"
            },
            "upscore-dsn2": {
              "content": "ScreenShot2017-09-16at9.58.01AM.dsn2.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "data": {
              "content": "ScreenShot2017-09-169.56.25M.png",
              "type": "image"
            }
          },
          "output": {
            "upscore-dsn5": {
              "content": "ScreenShot2017-09-169.56.25M-dsn5.png",
              "type": "image"
            },
            "upscore-dsn4": {
              "content": "ScreenShot2017-09-169.56.25M-dsn4.png",
              "type": "image"
            },
            "upscore-dsn1": {
              "content": "ScreenShot2017-09-169.56.25M-dsn1.png",
              "type": "image"
            },
            "upscore-dsn3": {
              "content": "ScreenShot2017-09-169.56.25M-dsn3.png",
              "type": "image"
            },
            "upscore-dsn2": {
              "content": "ScreenShot2017-09-169.56.25M-dsn2.png",
              "type": "image"
            }
          }
        }
      ],
      "primary_input": "data"
    },
    {
      "name": "FNS-Candy",
      "file": "FNS-Candy.mlmodel",
      "description": "Feedforward style transfer https://github.com/jcjohnson/fast-neural-style",
      "demo_link": "https://github.com/prisma-ai/torch2coreml",
      "reference_link": "http://cs.stanford.edu/people/jcjohns/eccv16/",
      "type": "Style Transfer",
      "license": "Free for personal or research use",
      "author": "Justin Johnson",
      "output": [
        {
          "type": "Image (Color 720 x 720)",
          "name": "outputImage",
          "description": "Stylized image"
        }
      ],
      "input": [
        {
          "type": "Image (Color 720 x 720)",
          "name": "inputImage",
          "description": "Image to stylize"
        }
      ],
      "size": "1.6 MB",
      "primary_output": "outputImage",
      "samples": [
        {
          "input": {
            "inputImage": {
              "content": "__FNS-Candy_IMG_3289_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-Candy_IMG_3292_PNG.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "inputImage": {
              "content": "__FNS-Candy_IMG_3275_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-Candy_IMG_3278_PNG.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "inputImage": {
              "content": "__FNS-Candy_IMG_3268_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-Candy_IMG_3271_PNG.png",
              "type": "image"
            }
          }
        }
      ],
      "primary_input": "inputImage"
    },
    {
      "name": "FNS-Feathers",
      "file": "FNS-Feathers.mlmodel",
      "description": "Feedforward style transfer https://github.com/jcjohnson/fast-neural-style",
      "demo_link": "https://github.com/prisma-ai/torch2coreml",
      "reference_link": "http://cs.stanford.edu/people/jcjohns/eccv16/",
      "type": "Style Transfer",
      "license": "Free for personal or research use",
      "author": "Justin Johnson",
      "output": [
        {
          "type": "Image (Color 720 x 720)",
          "name": "outputImage",
          "description": "Stylized image"
        }
      ],
      "input": [
        {
          "type": "Image (Color 720 x 720)",
          "name": "inputImage",
          "description": "Image to stylize"
        }
      ],
      "size": "1.6 MB",
      "primary_output": "outputImage",
      "samples": [
        {
          "input": {
            "inputImage": {
              "content": "__FNS-Feathers_IMG_3296_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-Feathers_IMG_3302_PNG.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "inputImage": {
              "content": "__FNS-Feathers_IMG_3282_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-Feathers_IMG_3288_PNG.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "inputImage": {
              "content": "__FNS-Feathers_IMG_3303_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-Feathers_IMG_3267_PNG.png",
              "type": "image"
            }
          }
        }
      ],
      "primary_input": "inputImage"
    },
    {
      "name": "FNS-La-Muse",
      "file": "FNS-La-Muse.mlmodel",
      "description": "Feedforward style transfer https://github.com/jcjohnson/fast-neural-style",
      "demo_link": "https://github.com/prisma-ai/torch2coreml",
      "reference_link": "http://cs.stanford.edu/people/jcjohns/eccv16/",
      "type": "Style Transfer",
      "license": "Free for personal or research use",
      "author": "Justin Johnson",
      "output": [
        {
          "type": "Image (Color 720 x 720)",
          "name": "outputImage",
          "description": "Stylized image"
        }
      ],
      "input": [
        {
          "type": "Image (Color 720 x 720)",
          "name": "inputImage",
          "description": "Image to stylize"
        }
      ],
      "size": "1.6 MB",
      "primary_output": "outputImage",
      "samples": [
        {
          "input": {
            "inputImage": {
              "content": "__FNS-La-Muse_IMG_3282_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-La-Muse_IMG_3287_PNG.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "inputImage": {
              "content": "__FNS-La-Muse_IMG_3275_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-La-Muse_IMG_3280_PNG.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "inputImage": {
              "content": "__FNS-La-Muse_IMG_3296_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-La-Muse_IMG_3301_PNG.png",
              "type": "image"
            }
          }
        }
      ],
      "primary_input": "inputImage"
    },
    {
      "name": "FNS-The-Scream",
      "file": "FNS-The-Scream.mlmodel",
      "description": "Feedforward style transfer https://github.com/jcjohnson/fast-neural-style",
      "demo_link": "https://github.com/prisma-ai/torch2coreml",
      "reference_link": "http://cs.stanford.edu/people/jcjohns/eccv16/",
      "type": "Style Transfer",
      "license": "Free for personal or research use",
      "author": "Justin Johnson",
      "output": [
        {
          "type": "Image (Color 720 x 720)",
          "name": "outputImage",
          "description": "Stylized image"
        }
      ],
      "input": [
        {
          "type": "Image (Color 720 x 720)",
          "name": "inputImage",
          "description": "Image to stylize"
        }
      ],
      "size": "1.6 MB",
      "primary_output": "outputImage",
      "samples": [
        {
          "input": {
            "inputImage": {
              "content": "__FNS-The-Scream_IMG_3268_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-The-Scream_IMG_3270_PNG.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "inputImage": {
              "content": "__FNS-The-Scream_IMG_3289_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-The-Scream_IMG_3291_PNG.png",
              "type": "image"
            }
          }
        }
      ],
      "primary_input": "inputImage"
    },
    {
      "name": "FNS-Udnie",
      "file": "FNS-Udnie.mlmodel",
      "description": "Feedforward style transfer https://github.com/jcjohnson/fast-neural-style",
      "demo_link": "https://github.com/prisma-ai/torch2coreml",
      "reference_link": "http://cs.stanford.edu/people/jcjohns/eccv16/",
      "type": "Style Transfer",
      "license": "Free for personal or research use",
      "author": "Justin Johnson",
      "output": [
        {
          "type": "Image (Color 720 x 720)",
          "name": "outputImage",
          "description": "Stylized image"
        }
      ],
      "input": [
        {
          "type": "Image (Color 720 x 720)",
          "name": "inputImage",
          "description": "Image to stylize"
        }
      ],
      "size": "1.6 MB",
      "primary_output": "outputImage",
      "samples": [
        {
          "input": {
            "inputImage": {
              "content": "__FNS-Udnie_IMG_3296_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-Udnie_IMG_3300_PNG.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "inputImage": {
              "content": "__FNS-Udnie_IMG_3303_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-Udnie_IMG_3265_PNG.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "inputImage": {
              "content": "__FNS-Udnie_IMG_3282_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-Udnie_IMG_3286_PNG.png",
              "type": "image"
            }
          }
        }
      ],
      "primary_input": "inputImage"
    },
    {
      "name": "FNS-Mosaic",
      "file": "FNS-Mosaic.mlmodel",
      "description": "Feedforward style transfer https://github.com/jcjohnson/fast-neural-style",
      "demo_link": "https://github.com/prisma-ai/torch2coreml",
      "reference_link": "http://cs.stanford.edu/people/jcjohns/eccv16/",
      "type": "Style Transfer",
      "license": "Free for personal or research use",
      "author": "Justin Johnson",
      "output": [
        {
          "type": "Image (Color 720 x 720)",
          "name": "outputImage",
          "description": "Stylized image"
        }
      ],
      "input": [
        {
          "type": "Image (Color 720 x 720)",
          "name": "inputImage",
          "description": "Image to stylize"
        }
      ],
      "size": "1.6 MB",
      "primary_output": "outputImage",
      "samples": [
        {
          "input": {
            "inputImage": {
              "content": "__FNS-Mosaic_IMG_3303_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-Mosaic_IMG_3263_PNG.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "inputImage": {
              "content": "__FNS-Mosaic_IMG_3296_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-Mosaic_IMG_3297_PNG.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "inputImage": {
              "content": "__FNS-Mosaic_IMG_3275_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-Mosaic_IMG_3276_PNG.png",
              "type": "image"
            }
          }
        }
      ],
      "primary_input": "inputImage"
    },
    {
      "name": "MessageClassifier",
      "file": "MessageClassifier.mlmodel",
      "description": "Detect whether a message is spam.",
      "download_link": "https://github.com/gkswamy98/imessage-spam-detection/blob/master/MessageClassifier.mlmodel",
      "demo_link": "https://github.com/gkswamy98/imessage-spam-detection/tree/master",
      "reference_link": "http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/",
      "type": "text",
      "input": [
        {
          "type": "MultiArray (Double 8713)",
          "name": "message"
        }
      ],
      "output": [
        {
          "type": "String",
          "name": "label"
        },
        {
          "type": "Dictionary (String -> Double)",
          "name": "classProbability"
        }
      ],
      "size": "68.2 KB",
      "primary_output": "label",
      "samples": [
        {
          "input": {
            "message": {
              "content": "URGENT! You have won a 1 week FREE membership in our Â£100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18",
              "type": "text"
            }
          },
          "output": {
            "classProbability": {},
            "label": {
              "content": "spam",
              "type": "text"
            }
          }
        },
        {
          "input": {
            "message": {
              "content": "Lol your always so convincing.",
              "type": "text"
            }
          },
          "output": {
            "classProbability": {},
            "label": {
              "content": "ham",
              "type": "text"
            }
          }
        }
      ],
      "primary_input": "message"
    }
  ]
}