{
  "types": [
    "Object Detection",
    "Style Transfer",
    "text",
    "others"
  ],
  "model_download_url_prefix": "https://s3-us-west-2.amazonaws.com/coreml-models/",
  "models": [
    {
      "name": "MobileNet",
      "file": "MobileNet.mlmodel",
      "description": "The network from the paper \\'MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\\', trained on the ImageNet dataset.",
      "download_link": "https://github.com/hollance/MobileNet-CoreML/raw/master/MobileNet.mlmodel",
      "demo_link": "https://github.com/hollance/MobileNet-CoreML",
      "reference_link": "https://arxiv.org/abs/1704.04861",
      "type": "Object Detection",
      "license": "Unknown",
      "author": "Original paper: Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam. Caffe implementation: shicai",
      "output": [
        {
          "type": "Dictionary (String -> Double)",
          "name": "prob",
          "description": "Probability of each category"
        },
        {
          "type": "String",
          "name": "classLabel",
          "description": "Most likely image category"
        }
      ],
      "input": [
        {
          "type": "Image (Color 224 x 224)",
          "name": "data",
          "description": "Input image to be classified"
        }
      ],
      "size": "16.4 MB",
      "primary_output": "classLabel",
      "samples": [
        {
          "input": {
            "data": {
              "content": "beagles_sample.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "beagle",
              "type": "text"
            },
            "prob": {}
          }
        },
        {
          "input": {
            "data": {
              "content": "skyscraper_sample.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "skyscraper",
              "type": "text"
            },
            "prob": {}
          }
        },
        {
          "input": {
            "data": {
              "content": "ScreenShot2017-09-16at8.52.00PM.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "tiger cat",
              "type": "text"
            },
            "prob": {}
          }
        }
      ],
      "primary_input": "data"
    },
    {
      "name": "GoogLeNetPlaces",
      "file": "GoogLeNetPlaces.mlmodel",
      "description": "Detects the scene of an image from 205 categories such as airport, bedroom, forest, coast etc.",
      "download_link": "https://github.com/hollance/MobileNet-CoreML/raw/master/MobileNet.mlmodel",
      "demo_link": "https://github.com/chenyi1989/CoreMLDemo",
      "reference_link": "http://places.csail.mit.edu/index.html",
      "type": "Object Detection",
      "license": "Creative Common License. More information available at http://places.csail.mit.edu",
      "author": "B. Zhou, A. Lapedriza, J. Xiao, A. Torralba, and A. Oliva",
      "output": [
        {
          "type": "Dictionary (String -> Double)",
          "name": "sceneLabelProbs",
          "description": "Probability of each scene"
        },
        {
          "type": "String",
          "name": "sceneLabel",
          "description": "Most likely scene label"
        }
      ],
      "input": [
        {
          "type": "Image (Color 224 x 224)",
          "name": "sceneImage",
          "description": "Input image of scene to be classified"
        }
      ],
      "size": "23.6 MB",
      "primary_output": "sceneLabel",
      "samples": [
        {
          "input": {
            "sceneImage": {
              "content": "bamboo_forrest_sample.png",
              "type": "image"
            }
          },
          "output": {
            "sceneLabel": {
              "content": "bamboo forrest",
              "type": "text"
            },
            "sceneLabelProbs": {}
          }
        },
        {
          "input": {
            "sceneImage": {
              "content": "mountain_snowy_sample.png",
              "type": "image"
            }
          },
          "output": {
            "sceneLabel": {
              "content": "mountain snowy",
              "type": "text"
            },
            "sceneLabelProbs": {}
          }
        }
      ],
      "primary_input": "sceneImage"
    },
    {
      "name": "Inceptionv3",
      "file": "Inceptionv3.mlmodel",
      "description": "Detects the dominant objects present in an image from a set of 1000 categories such as trees, animals, food, vehicles, person etc. The top-5 error from the original publication is 5.6%.",
      "download_link": "https://github.com/yulingtianxia/Core-ML-Sample/blob/master/CoreMLSample/Inceptionv3.mlmodel",
      "demo_link": "https://github.com/yulingtianxia/Core-ML-Sample/",
      "reference_link": "https://arxiv.org/abs/1512.00567",
      "type": "Object Detection",
      "license": "MIT License. More information available at https://github.com/fchollet/keras/blob/master/LICENSE",
      "author": "Original Paper: Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, Zbigniew Wojna. Keras Implementation: Fran\\303\\247ois Chollet",
      "output": [
        {
          "type": "Dictionary (String -> Double)",
          "name": "classLabelProbs",
          "description": "Probability of each category"
        },
        {
          "type": "String",
          "name": "classLabel",
          "description": "Most likely image category"
        }
      ],
      "input": [
        {
          "type": "Image (Color 299 x 299)",
          "name": "image",
          "description": "Input image to be classified"
        }
      ],
      "size": "90.3 MB",
      "primary_output": "classLabel",
      "samples": [
        {
          "input": {
            "image": {
              "content": "steel_car_samples.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "steel car",
              "type": "text"
            },
            "classLabelProbs": {}
          }
        },
        {
          "input": {
            "image": {
              "content": "tabby_cat_sample.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "tabby cat",
              "type": "text"
            },
            "classLabelProbs": {}
          }
        },
        {
          "input": {
            "image": {
              "content": "flower_pot_samples.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "flower pot",
              "type": "text"
            },
            "classLabelProbs": {}
          }
        }
      ],
      "primary_input": "image"
    },
    {
      "name": "Resnet50",
      "file": "Resnet50.mlmodel",
      "description": "Detects the dominant objects present in an image from a set of 1000 categories such as trees, animals, food, vehicles, person etc. The top-5 error from the original publication is 7.8%.",
      "download_link": "https://github.com/ytakzk/CoreML-samples/blob/master/CoreML-samples/Resnet50.mlmodel",
      "demo_link": "https://github.com/atomic14/VisionCoreMLSample",
      "reference_link": "https://arxiv.org/abs/1512.03385",
      "type": "Object Detection",
      "license": "MIT License. More information available at https://github.com/fchollet/keras/blob/master/LICENSE",
      "author": "Original Paper: Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun. Keras Implementation: Fran\\303\\247ois Chollet",
      "output": [
        {
          "type": "Dictionary (String -> Double)",
          "name": "classLabelProbs",
          "description": "Probability of each category"
        },
        {
          "type": "String",
          "name": "classLabel",
          "description": "Most likely image category"
        }
      ],
      "input": [
        {
          "type": "Image (Color 224 x 224)",
          "name": "image",
          "description": "Input image of scene to be classified"
        }
      ],
      "size": "97.8 MB",
      "primary_output": "classLabel",
      "samples": [
        {
          "input": {
            "image": {
              "content": "coffee_mug_sample.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "coffee mug",
              "type": "text"
            },
            "classLabelProbs": {}
          }
        },
        {
          "input": {
            "image": {
              "content": "ScreenShot2017-09-16at8.28.57PM.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "toy poodle",
              "type": "text"
            },
            "classLabelProbs": {}
          }
        },
        {
          "input": {
            "image": {
              "content": "dam_sample.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "dam, dike",
              "type": "text"
            },
            "classLabelProbs": {}
          }
        }
      ],
      "primary_input": "image"
    },
    {
      "name": "VGG16",
      "file": "VGG16.mlmodel",
      "description": "Detects the dominant objects present in an image from a set of 1000 categories such as trees, animals, food, vehicles, person etc. The top-5 error from the original publication is 7.4%.",
      "download_link": "https://docs-assets.developer.apple.com/coreml/models/VGG16.mlmodel",
      "demo_link": "https://github.com/alaphao/CoreMLExample",
      "reference_link": "https://arxiv.org/abs/1409.1556",
      "type": "Object Detection",
      "license": "Creative Commons Attribution 4.0 International(CC BY 4.0). More information available at https://creativecommons.org/licenses/by/4.0/",
      "author": "Original Paper: Karen Simonyan & Andrew Zisserman. Keras Implementation: Fran\\303\\247ois Chollet",
      "output": [
        {
          "type": "Dictionary (String -> Double)",
          "name": "classLabelProbs",
          "description": "Probability of each category"
        },
        {
          "type": "String",
          "name": "classLabel",
          "description": "Most likely image category"
        }
      ],
      "input": [
        {
          "type": "Image (Color 224 x 224)",
          "name": "image",
          "description": "Input image to be classified"
        }
      ],
      "size": "527.8 MB",
      "primary_output": "classLabel",
      "samples": [
        {
          "input": {
            "image": {
              "content": "dock_sample.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "dock",
              "type": "text"
            },
            "classLabelProbs": {}
          }
        },
        {
          "input": {
            "image": {
              "content": "fountain_sample.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "fountain",
              "type": "text"
            },
            "classLabelProbs": {}
          }
        }
      ],
      "primary_input": "image"
    },
    {
      "name": "CarRecognition",
      "file": "CarRecognition.mlmodel",
      "description": "Predict the brand & model of a car.",
      "download_link": "https://github.com/likedan/Core-ML-Car-Recognition/blob/master/Convert/CarRecognition.mlmodel",
      "demo_link": "https://github.com/likedan/Core-ML-Car-Recognition",
      "reference_link": "http://mmlab.ie.cuhk.edu.hk/datasets/comp_cars/index.html",
      "type": "Object Detection",
      "license": "MIT",
      "author": "Audebert, Nicolas and Le Saux, Bertrand and Lefevre Sebastien",
      "output": [
        {
          "type": "Dictionary (String -> Double)",
          "name": "prob",
          "description": "The probabilities that the input image is a car."
        },
        {
          "type": "String",
          "name": "classLabel",
          "description": "The most likely type of car, for the given input."
        }
      ],
      "input": [
        {
          "type": "Image (Color 224 x 224)",
          "name": "data",
          "description": "An image of a car."
        }
      ],
      "size": "24.5 MB",
      "primary_output": "classLabel",
      "samples": [
        {
          "input": {
            "data": {
              "content": "mercedes_e_convertable.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "Mercedes E class convertable",
              "type": "text"
            },
            "prob": {}
          }
        },
        {
          "input": {
            "data": {
              "content": "camaro_samples.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "Camaros",
              "type": "text"
            },
            "prob": {}
          }
        },
        {
          "input": {
            "data": {
              "content": "BMW_m5_samples.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "BMW M5",
              "type": "text"
            },
            "prob": {}
          }
        }
      ],
      "primary_input": "data"
    },
    {
      "name": "AgeNet",
      "file": "AgeNet.mlmodel",
      "description": "Age Classification using Convolutional Neural Networks",
      "download_link": "https://s3-us-west-2.amazonaws.com/coreml-models/AgeNet.mlmodel",
      "demo_link": "https://github.com/cocoa-ai/FacesVisionDemo",
      "reference_link": "http://www.openu.ac.il/home/hassner/projects/cnn_agegender/",
      "type": "Object Detection",
      "license": "Unknown",
      "author": "Gil Levi and Tal Hassner",
      "output": [
        {
          "type": "Dictionary (String -> Double)",
          "name": "prob",
          "description": "The probabilities for each age, for the given input."
        },
        {
          "type": "String",
          "name": "classLabel",
          "description": "The most likely age, for the given input."
        }
      ],
      "input": [
        {
          "type": "Image (Color 227 x 227)",
          "name": "data",
          "description": "An image with a face."
        }
      ],
      "size": "43.5 MB",
      "primary_output": "classLabel",
      "samples": [
        {
          "input": {
            "data": {
              "content": "ScreenShot2017-09-154.59.42PM.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "60-100",
              "type": "text"
            },
            "prob": {}
          }
        },
        {
          "input": {
            "data": {
              "content": "ScreenShot20170915at4.54.34.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "25-32",
              "type": "text"
            },
            "prob": {}
          }
        }
      ],
      "primary_input": "data"
    },
    {
      "name": "GenderNet",
      "file": "GenderNet.mlmodel",
      "description": "Gender Classification using Convolutional Neural Networks",
      "download_link": "https://drive.google.com/file/d/0B1ghKa_MYL6mYkNsZHlyc2ZuaFk/view?usp=sharing",
      "demo_link": "https://github.com/cocoa-ai/FacesVisionDemo",
      "reference_link": "http://www.openu.ac.il/home/hassner/projects/cnn_agegender/",
      "type": "Object Detection",
      "license": "Unknown",
      "author": "Gil Levi and Tal Hassner",
      "output": [
        {
          "type": "Dictionary (String -> Double)",
          "name": "prob",
          "description": "The probabilities for each gender, for the given input."
        },
        {
          "type": "String",
          "name": "classLabel",
          "description": "The most likely gender, for the given input."
        }
      ],
      "input": [
        {
          "type": "Image (Color 227 x 227)",
          "name": "data",
          "description": "An image with a face."
        }
      ],
      "size": "43.5 MB",
      "primary_output": "classLabel",
      "samples": [
        {
          "input": {
            "data": {
              "content": "ScreenShot20170915at4.54.34.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "Male",
              "type": "text"
            },
            "prob": {}
          }
        },
        {
          "input": {
            "data": {
              "content": "ScreenShot2017-09-154.59.42PM.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "Female",
              "type": "text"
            },
            "prob": {}
          }
        }
      ],
      "primary_input": "data"
    },
    {
      "name": "MNIST",
      "file": "MNIST.mlmodel",
      "description": "Predicts a handwritten digit.",
      "download_link": "https://github.com/ph1ps/MNIST-CoreML/raw/master/MNISTPrediction/MNIST.mlmodel",
      "demo_link": "https://github.com/ph1ps/MNIST-CoreML",
      "reference_link": "http://yann.lecun.com/exdb/mnist/",
      "type": "Object Detection",
      "license": "MIT",
      "author": "Philipp Gabriel",
      "output": [
        {
          "type": "Dictionary (Int64 -> Double)",
          "name": "prediction",
          "description": "Array of predictions mapped to their indices"
        },
        {
          "type": "Int64",
          "name": "classLabel"
        }
      ],
      "input": [
        {
          "type": "Image (Gray scale 28 x 28)",
          "name": "image",
          "description": "Image to analyze"
        }
      ],
      "size": "2.3 MB",
      "primary_output": "classLabel",
      "samples": [
        {
          "input": {
            "image": {
              "content": "hand_writter_8.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "8",
              "type": "text"
            },
            "prediction": {}
          }
        },
        {
          "input": {
            "image": {
              "content": "hand_writter_6.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "6",
              "type": "text"
            },
            "prediction": {}
          }
        }
      ],
      "primary_input": "image"
    },
    {
      "name": "CNNEmotions",
      "file": "CNNEmotions.mlmodel",
      "description": "Emotion Recognition in the Wild via Convolutional Neural Networks and Mapped Binary Patterns",
      "download_link": "https://drive.google.com/file/d/0B1ghKa_MYL6mTlYtRGdXNFlpWDQ/view?usp=sharing",
      "demo_link": "https://github.com/cocoa-ai/FacesVisionDemo",
      "reference_link": "http://www.openu.ac.il/home/hassner/projects/cnn_emotions/",
      "type": "Object Detection",
      "license": "Unknown",
      "author": "Gil Levi and Tal Hassner",
      "output": [
        {
          "type": "Dictionary (String -> Double)",
          "name": "prob",
          "description": "The probabilities for each emotion, for the given input."
        },
        {
          "type": "String",
          "name": "classLabel",
          "description": "The most likely type of emotion, for the given input."
        }
      ],
      "input": [
        {
          "type": "Image (Color 224 x 224)",
          "name": "data",
          "description": "An image with a face."
        }
      ],
      "size": "475.0 MB",
      "primary_output": "classLabel",
      "samples": [
        {
          "input": {
            "data": {
              "content": "ScreenShot20170915at4.54.34.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "Fear",
              "type": "text"
            },
            "prob": {}
          }
        },
        {
          "input": {
            "data": {
              "content": "ScreenShot2017-09-154.59.42PM.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "Angry",
              "type": "text"
            },
            "prob": {}
          }
        }
      ],
      "primary_input": "data"
    },
    {
      "name": "VisualSentimentCNN",
      "file": "VisualSentimentCNN.mlmodel",
      "description": "Fine-tuning CNNs for Visual Sentiment Prediction",
      "download_link": "https://drive.google.com/open?id=0B1ghKa_MYL6mZ0dITW5uZlgyNTg",
      "demo_link": "https://github.com/cocoa-ai/SentimentVisionDemo",
      "reference_link": "http://www.sciencedirect.com/science/article/pii/S0262885617300355?via%3Dihub",
      "type": "Object Detection",
      "license": "MIT",
      "author": "Image Processing Group - BarcelonaTECH - UPC",
      "output": [
        {
          "type": "Dictionary (String -> Double)",
          "name": "prob",
          "description": "The probabilities for each sentiment, for the given input."
        },
        {
          "type": "String",
          "name": "classLabel",
          "description": "The most likely sentiment, for the given input."
        }
      ],
      "input": [
        {
          "type": "Image (Color 227 x 227)",
          "name": "data",
          "description": "An image."
        }
      ],
      "size": "217.0 MB",
      "primary_output": "prob",
      "samples": [
        {
          "input": {
            "data": {
              "content": "sentiment_screenshot.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "positive",
              "type": "text"
            },
            "prob": {
              "content": "{\n\tpositive: 90.9%\n\tnegative: 9.1%\n}",
              "type": "text"
            }
          }
        },
        {
          "input": {
            "data": {
              "content": "sentiment_screenshot2.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "negative",
              "type": "text"
            },
            "prob": {
              "content": "{\n\tpositive: 21.7%\n\tnegative: 78.3%\n}",
              "type": "text"
            }
          }
        }
      ],
      "primary_input": "data"
    },
    {
      "name": "Food101",
      "file": "Food101.mlmodel",
      "description": "This model takes a picture of a food and predicts its name",
      "download_link": "https://drive.google.com/open?id=0B5TjkH3njRqnVjBPZGRZbkNITjA",
      "demo_link": "https://github.com/ph1ps/Food101-CoreML",
      "reference_link": "http://visiir.lip6.fr/explore",
      "type": "Object Detection",
      "license": "Unknown",
      "author": "Philipp Gabriel",
      "output": [
        {
          "type": "Dictionary (String -> Double)",
          "name": "foodConfidence",
          "description": "Confidence and label of predicted food"
        },
        {
          "type": "String",
          "name": "classLabel",
          "description": "Label of predicted food"
        }
      ],
      "input": [
        {
          "type": "MultiArray (Double 3 x 299 x 299)",
          "name": "image",
          "description": "Image of a food"
        }
      ],
      "size": "83.3 MB",
      "primary_output": "classLabel",
      "samples": [
        {
          "input": {
            "image": {
              "content": "applepie-screen.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "apple pie",
              "type": "text"
            },
            "foodConfidence": {}
          }
        },
        {
          "input": {
            "image": {
              "content": "lobster-screen.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "lobster roll sandwish",
              "type": "text"
            },
            "foodConfidence": {}
          }
        },
        {
          "input": {
            "image": {
              "content": "ribs-screen.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "baby back ribs",
              "type": "text"
            },
            "foodConfidence": {}
          }
        },
        {
          "input": {
            "image": {
              "content": "steak-screen.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "steak",
              "type": "text"
            },
            "foodConfidence": {}
          }
        }
      ],
      "primary_input": "image"
    },
    {
      "name": "Oxford102",
      "file": "Oxford102.mlmodel",
      "description": "Classifying images in the Oxford 102 flower dataset with CNNs",
      "download_link": "https://drive.google.com/file/d/0B1ghKa_MYL6meDBHT2NaZGxkNzQ/view?usp=sharing",
      "demo_link": "https://github.com/cocoa-ai/FlowersVisionDemo",
      "reference_link": "http://jimgoo.com/flower-power/",
      "type": "Object Detection",
      "license": "Unknown",
      "author": "Jimmie Goode",
      "output": [
        {
          "type": "Dictionary (String -> Double)",
          "name": "prob",
          "description": "The probabilities for each flower type, for the given input."
        },
        {
          "type": "String",
          "name": "classLabel",
          "description": "The most likely type of flower, for the given input."
        }
      ],
      "input": [
        {
          "type": "Image (Color 227 x 227)",
          "name": "data",
          "description": "An image of a flower."
        }
      ],
      "size": "218.5 MB",
      "primary_output": "classLabel",
      "samples": [
        {
          "input": {
            "data": {
              "content": "rose_screen.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "rose",
              "type": "text"
            },
            "prob": {}
          }
        },
        {
          "input": {
            "data": {
              "content": "morning_glory_screen.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "morning_glory",
              "type": "text"
            },
            "prob": {}
          }
        }
      ],
      "primary_input": "data"
    },
    {
      "name": "FlickrStyle",
      "file": "FlickrStyle.mlmodel",
      "description": "Finetuning CaffeNet on Flickr Style",
      "download_link": "https://drive.google.com/file/d/0B1ghKa_MYL6meDBHT2NaZGxkNzQ/view?usp=sharing",
      "demo_link": "https://github.com/cocoa-ai/StylesVisionDemo",
      "reference_link": "http://sergeykarayev.com/files/1311.3715v3.pdf",
      "type": "Object Detection",
      "license": "Unknown",
      "author": "Sergey Karayev",
      "output": [
        {
          "type": "Dictionary (String -> Double)",
          "name": "prob",
          "description": "The probabilities for each style type, for the given input."
        },
        {
          "type": "String",
          "name": "classLabel",
          "description": "The most likely style of image, for the given input."
        }
      ],
      "input": [
        {
          "type": "Image (Color 227 x 227)",
          "name": "data",
          "description": "An image."
        }
      ],
      "size": "217.2 MB",
      "primary_output": "classLabel",
      "samples": [
        {
          "input": {
            "data": {
              "content": "ScreenShot2017-09-16at1.19.30AM.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "Pastel",
              "type": "text"
            },
            "prob": {}
          }
        },
        {
          "input": {
            "data": {
              "content": "vintage_image_sample.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {
              "content": "Vintage",
              "type": "text"
            },
            "prob": {}
          }
        }
      ],
      "primary_input": "data"
    },
    {
      "name": "RN1015k500",
      "file": "RN1015k500.mlmodel",
      "description": "Predict the location where a picture was taken.",
      "download_link": "https://s3.amazonaws.com/aws-bigdata-blog/artifacts/RN1015k500/RN1015k500.mlmodel",
      "demo_link": "https://github.com/awslabs/MXNet2CoreML_iOS_sample_app",
      "reference_link": "https://aws.amazon.com/blogs/ai/estimating-the-location-of-images-using-mxnet-and-multimedia-commons-dataset-on-aws-ec2",
      "type": "Object Detection",
      "input": [
        {
          "type": "Image (Color 224 x 224)",
          "name": "data"
        }
      ],
      "output": [
        {
          "type": "Dictionary (String -> Double)",
          "name": "softmax_output"
        },
        {
          "type": "String",
          "name": "classLabel"
        }
      ],
      "size": "284.4 MB",
      "primary_output": "softmax_output",
      "samples": [
        {
          "input": {
            "data": {
              "content": "ScreenShot2017-09-161.40.24AM.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {},
            "softmax_output": {
              "content": "ScreenShot2017-09-161.40.24AM_out.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "data": {
              "content": "ScreenShot2017-09-1611.41.59AM.png",
              "type": "image"
            }
          },
          "output": {
            "classLabel": {},
            "softmax_output": {
              "content": "ScreenShot2017-09-1611.41.59AM_out.png",
              "type": "image"
            }
          }
        }
      ],
      "primary_input": "data"
    },
    {
      "name": "HED_so",
      "file": "HED_so.mlmodel",
      "description": "Holistically-Nested Edge Detection. Side outputs",
      "download_link": "https://github.com/s1ddok/HED-CoreML/blob/master/HED-CoreML/Models/HED_so.mlmodel",
      "demo_link": "https://github.com/s1ddok/HED-CoreML",
      "reference_link": "http://dl.acm.org/citation.cfm?id=2654889",
      "type": "Style Transfer",
      "license": "Unknown",
      "author": "Original paper: Xie, Saining and Tu, Zhuowen. Caffe implementation: Yangqing Jia. CoreML port: Andrey Volodin",
      "output": [
        {
          "type": "MultiArray (Double)",
          "name": "upscore-dsn1",
          "description": "Tensor that can be treated as single-channel texture where each pixel represents the probability of edge there. Should be normalized before usage (i.e. with sigmoid function)"
        },
        {
          "type": "MultiArray (Double)",
          "name": "upscore-dsn2",
          "description": "Tensor that can be treated as single-channel texture where each pixel represents the probability of edge there. Should be normalized before usage (i.e. with sigmoid function)"
        },
        {
          "type": "MultiArray (Double)",
          "name": "upscore-dsn3",
          "description": "Tensor that can be treated as single-channel texture where each pixel represents the probability of edge there. Should be normalized before usage (i.e. with sigmoid function)"
        },
        {
          "type": "MultiArray (Double)",
          "name": "upscore-dsn4",
          "description": "Tensor that can be treated as single-channel texture where each pixel represents the probability of edge there. Should be normalized before usage (i.e. with sigmoid function)"
        },
        {
          "type": "MultiArray (Double)",
          "name": "upscore-dsn5",
          "description": "Tensor that can be treated as single-channel texture where each pixel represents the probability of edge there. Should be normalized before usage (i.e. with sigmoid function)"
        }
      ],
      "input": [
        {
          "type": "Image (Color 500 x 500)",
          "name": "data",
          "description": "Input image to be edge-detected. Must be exactly 500x500 pixels."
        }
      ],
      "size": "56.1 MB",
      "primary_output": "upscore-dsn3",
      "samples": [
        {
          "input": {
            "data": {
              "content": "ScreenShot2017-09-16at9.58.01AM.png",
              "type": "image"
            }
          },
          "output": {
            "upscore-dsn5": {
              "content": "ScreenShot2017-09-16at9.58.01AM.dsn5.png",
              "type": "image"
            },
            "upscore-dsn4": {
              "content": "ScreenShot2017-09-16at9.58.01AM.dsn4.png",
              "type": "image"
            },
            "upscore-dsn1": {
              "content": "ScreenShot2017-09-16at9.58.01AM.dsn1.png",
              "type": "image"
            },
            "upscore-dsn3": {
              "content": "ScreenShot2017-09-16at9.58.01AM.dsn3.png",
              "type": "image"
            },
            "upscore-dsn2": {
              "content": "ScreenShot2017-09-16at9.58.01AM.dsn2.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "data": {
              "content": "ScreenShot2017-09-169.56.25M.png",
              "type": "image"
            }
          },
          "output": {
            "upscore-dsn5": {
              "content": "ScreenShot2017-09-169.56.25M-dsn5.png",
              "type": "image"
            },
            "upscore-dsn4": {
              "content": "ScreenShot2017-09-169.56.25M-dsn4.png",
              "type": "image"
            },
            "upscore-dsn1": {
              "content": "ScreenShot2017-09-169.56.25M-dsn1.png",
              "type": "image"
            },
            "upscore-dsn3": {
              "content": "ScreenShot2017-09-169.56.25M-dsn3.png",
              "type": "image"
            },
            "upscore-dsn2": {
              "content": "ScreenShot2017-09-169.56.25M-dsn2.png",
              "type": "image"
            }
          }
        }
      ],
      "primary_input": "data"
    },
    {
      "name": "FNS-Candy",
      "file": "FNS-Candy.mlmodel",
      "description": "Feedforward style transfer https://github.com/jcjohnson/fast-neural-style",
      "demo_link": "https://github.com/prisma-ai/torch2coreml",
      "reference_link": "http://cs.stanford.edu/people/jcjohns/eccv16/",
      "type": "Style Transfer",
      "license": "Free for personal or research use",
      "author": "Justin Johnson",
      "output": [
        {
          "type": "Image (Color 720 x 720)",
          "name": "outputImage",
          "description": "Stylized image"
        }
      ],
      "input": [
        {
          "type": "Image (Color 720 x 720)",
          "name": "inputImage",
          "description": "Image to stylize"
        }
      ],
      "size": "1.6 MB",
      "primary_output": "outputImage",
      "samples": [
        {
          "input": {
            "inputImage": {
              "content": "__FNS-Candy_IMG_3289_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-Candy_IMG_3292_PNG.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "inputImage": {
              "content": "__FNS-Candy_IMG_3275_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-Candy_IMG_3278_PNG.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "inputImage": {
              "content": "__FNS-Candy_IMG_3268_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-Candy_IMG_3271_PNG.png",
              "type": "image"
            }
          }
        }
      ],
      "primary_input": "inputImage"
    },
    {
      "name": "FNS-Feathers",
      "file": "FNS-Feathers.mlmodel",
      "description": "Feedforward style transfer https://github.com/jcjohnson/fast-neural-style",
      "demo_link": "https://github.com/prisma-ai/torch2coreml",
      "reference_link": "http://cs.stanford.edu/people/jcjohns/eccv16/",
      "type": "Style Transfer",
      "license": "Free for personal or research use",
      "author": "Justin Johnson",
      "output": [
        {
          "type": "Image (Color 720 x 720)",
          "name": "outputImage",
          "description": "Stylized image"
        }
      ],
      "input": [
        {
          "type": "Image (Color 720 x 720)",
          "name": "inputImage",
          "description": "Image to stylize"
        }
      ],
      "size": "1.6 MB",
      "primary_output": "outputImage",
      "samples": [
        {
          "input": {
            "inputImage": {
              "content": "__FNS-Feather_IMG_3296_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-Feather_IMG_3302_PNG.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "inputImage": {
              "content": "__FNS-Feather_IMG_3282_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-Feather_IMG_3288_PNG.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "inputImage": {
              "content": "__FNS-Feather_IMG_3303_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-Feather_IMG_3267_PNG.png",
              "type": "image"
            }
          }
        }
      ],
      "primary_input": "inputImage"
    },
    {
      "name": "FNS-La-Muse",
      "file": "FNS-La-Muse.mlmodel",
      "description": "Feedforward style transfer https://github.com/jcjohnson/fast-neural-style",
      "demo_link": "https://github.com/prisma-ai/torch2coreml",
      "reference_link": "http://cs.stanford.edu/people/jcjohns/eccv16/",
      "type": "Style Transfer",
      "license": "Free for personal or research use",
      "author": "Justin Johnson",
      "output": [
        {
          "type": "Image (Color 720 x 720)",
          "name": "outputImage",
          "description": "Stylized image"
        }
      ],
      "input": [
        {
          "type": "Image (Color 720 x 720)",
          "name": "inputImage",
          "description": "Image to stylize"
        }
      ],
      "size": "1.6 MB",
      "primary_output": "outputImage",
      "samples": [
        {
          "input": {
            "inputImage": {
              "content": "__FNS-La-Muse_IMG_3275_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-La-Muse_IMG_3280_PNG.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "inputImage": {
              "content": "__FNS-La-Muse_IMG_3282_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-La-Muse_IMG_3287_PNG.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "inputImage": {
              "content": "__FNS-La-Muse_IMG_3296_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-La-Muse_IMG_3301_PNG.png",
              "type": "image"
            }
          }
        }
      ],
      "primary_input": "inputImage"
    },
    {
      "name": "FNS-The-Scream",
      "file": "FNS-The-Scream.mlmodel",
      "description": "Feedforward style transfer https://github.com/jcjohnson/fast-neural-style",
      "demo_link": "https://github.com/prisma-ai/torch2coreml",
      "reference_link": "http://cs.stanford.edu/people/jcjohns/eccv16/",
      "type": "Style Transfer",
      "license": "Free for personal or research use",
      "author": "Justin Johnson",
      "output": [
        {
          "type": "Image (Color 720 x 720)",
          "name": "outputImage",
          "description": "Stylized image"
        }
      ],
      "input": [
        {
          "type": "Image (Color 720 x 720)",
          "name": "inputImage",
          "description": "Image to stylize"
        }
      ],
      "size": "1.6 MB",
      "primary_output": "outputImage",
      "samples": [
        {
          "input": {
            "inputImage": {
              "content": "__FNS-The-Scream_IMG_3268_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-The-Scream_IMG_3270_PNG.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "inputImage": {
              "content": "__FNS-The-Scream_IMG_3289_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-The-Scream_IMG_3291_PNG.png",
              "type": "image"
            }
          }
        }
      ],
      "primary_input": "inputImage"
    },
    {
      "name": "FNS-Udnie",
      "file": "FNS-Udnie.mlmodel",
      "description": "Feedforward style transfer https://github.com/jcjohnson/fast-neural-style",
      "demo_link": "https://github.com/prisma-ai/torch2coreml",
      "reference_link": "http://cs.stanford.edu/people/jcjohns/eccv16/",
      "type": "Style Transfer",
      "license": "Free for personal or research use",
      "author": "Justin Johnson",
      "output": [
        {
          "type": "Image (Color 720 x 720)",
          "name": "outputImage",
          "description": "Stylized image"
        }
      ],
      "input": [
        {
          "type": "Image (Color 720 x 720)",
          "name": "inputImage",
          "description": "Image to stylize"
        }
      ],
      "size": "1.6 MB",
      "primary_output": "outputImage",
      "samples": [
        {
          "input": {
            "inputImage": {
              "content": "__FNS-Udnie_IMG_3296_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-Udnie_IMG_3300_PNG.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "inputImage": {
              "content": "__FNS-Udnie_IMG_3303_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-Udnie_IMG_3265_PNG.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "inputImage": {
              "content": "__FNS-Udnie_IMG_3282_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-Udnie_IMG_3286_PNG.png",
              "type": "image"
            }
          }
        }
      ],
      "primary_input": "inputImage"
    },
    {
      "name": "FNS-Mosaic",
      "file": "FNS-Mosaic.mlmodel",
      "description": "Feedforward style transfer https://github.com/jcjohnson/fast-neural-style",
      "demo_link": "https://github.com/prisma-ai/torch2coreml",
      "reference_link": "http://cs.stanford.edu/people/jcjohns/eccv16/",
      "type": "Style Transfer",
      "license": "Free for personal or research use",
      "author": "Justin Johnson",
      "output": [
        {
          "type": "Image (Color 720 x 720)",
          "name": "outputImage",
          "description": "Stylized image"
        }
      ],
      "input": [
        {
          "type": "Image (Color 720 x 720)",
          "name": "inputImage",
          "description": "Image to stylize"
        }
      ],
      "size": "1.6 MB",
      "primary_output": "outputImage",
      "samples": [
        {
          "input": {
            "inputImage": {
              "content": "__FNS-Mosaic_IMG_3303_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-Mosaic_IMG_3263_PNG.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "inputImage": {
              "content": "__FNS-Mosaic_IMG_3296_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-Mosaic_IMG_3297_PNG.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "inputImage": {
              "content": "__FNS-Mosaic_IMG_3275_PNG.png",
              "type": "image"
            }
          },
          "output": {
            "outputImage": {
              "content": "__FNS-Mosaic_IMG_3276_PNG.png",
              "type": "image"
            }
          }
        }
      ],
      "primary_input": "inputImage"
    },
    {
      "name": "AnimeScale2x",
      "file": "AnimeScale2x.mlmodel",
      "description": "Process a bicubic-scaled anime-style artwork",
      "demo_link": "https://github.com/imxieyi/waifu2x-ios",
      "reference_link": "https://arxiv.org/abs/1501.00092",
      "type": "Style Transfer",
      "license": "MIT",
      "author": "Original paper: Chao Dong, Chen Change Loy, Kaiming He, Xiaoou Tang. Caffe implementation: lltcggie",
      "output": [
        {
          "type": "MultiArray (Double)",
          "name": "conv7",
          "description": "Output image"
        }
      ],
      "input": [
        {
          "type": "MultiArray (Double 3 x 142 x 142)",
          "name": "input",
          "description": "Input image"
        }
      ],
      "size": "1.1 MB",
      "primary_output": "conv7",
      "samples": [
        {
          "input": {
            "input": {
              "content": "waifu2x_small_noisy_sample.png",
              "type": "image"
            }
          },
          "output": {
            "conv7": {
              "content": "waifu2x_small_noisy_sample_output.png",
              "type": "image"
            }
          }
        },
        {
          "input": {
            "input": {
              "content": "waifu2x_small_sample_output.png",
              "type": "image"
            }
          },
          "output": {
            "conv7": {
              "content": "waifu2x_small_noisy_sample_output.png",
              "type": "image"
            }
          }
        }
      ],
      "primary_input": "input"
    },
    {
      "name": "MessageClassifier",
      "file": "MessageClassifier.mlmodel",
      "description": "Detect whether a message is spam.",
      "demo_link": "https://github.com/gkswamy98/imessage-spam-detection/tree/master",
      "reference_link": "http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/",
      "type": "text",
      "input": [
        {
          "type": "MultiArray (Double 8713)",
          "name": "message"
        }
      ],
      "output": [
        {
          "type": "String",
          "name": "label"
        },
        {
          "type": "Dictionary (String -> Double)",
          "name": "classProbability"
        }
      ],
      "size": "68.2 KB",
      "primary_output": "label",
      "samples": [
        {
          "input": {
            "message": {
              "content": "URGENT! You have won a 1 week FREE membership in our Â£100,000 Prize Jackpot!",
              "type": "text"
            }
          },
          "output": {
            "classProbability": {},
            "label": {
              "content": "spam",
              "type": "text"
            }
          }
        },
        {
          "input": {
            "message": {
              "content": "Lol your always so convincing.",
              "type": "text"
            }
          },
          "output": {
            "classProbability": {},
            "label": {
              "content": "ham",
              "type": "text"
            }
          }
        },
        {
          "input": {
            "message": {
              "content": "What time you coming down later?",
              "type": "text"
            }
          },
          "output": {
            "classProbability": {},
            "label": {
              "content": "ham",
              "type": "text"
            }
          }
        },
        {
          "input": {
            "message": {
              "content": "SMS. ac Blind Date 4U!: Rodds1 is 21/m from Aberdeen",
              "type": "text"
            }
          },
          "output": {
            "classProbability": {},
            "label": {
              "content": "spam",
              "type": "text"
            }
          }
        }
      ],
      "primary_input": "message"
    },
    {
      "name": "Exermote",
      "file": "Exermote.mlmodel",
      "description": "Predicts the exercise, when iPhone is worn on right upper arm.",
      "download_link": "https://github.com/Lausbert/Exermote/raw/master/ExermoteInference/ExermoteCoreML/ExermoteCoreML/Model/Exermote.mlmodel",
      "demo_link": "https://github.com/Lausbert/Exermote/tree/master/ExermoteInference",
      "reference_link": "http://lausbert.com/2017/08/03/exermote/",
      "type": "others",
      "license": "MIT",
      "author": "Stephan Lerner",
      "output": [
        {
          "type": "MultiArray (Double 4)",
          "name": "scores",
          "description": "Probability of different exercises (Break, Burpee, Situp, Squat)"
        },
        {
          "type": "MultiArray (Double 32)",
          "name": "lstm_1_h_out"
        },
        {
          "type": "MultiArray (Double 32)",
          "name": "lstm_1_c_out"
        },
        {
          "type": "MultiArray (Double 32)",
          "name": "lstm_2_h_out"
        },
        {
          "type": "MultiArray (Double 32)",
          "name": "lstm_2_c_out"
        }
      ],
      "input": [
        {
          "type": "MultiArray (Double 12)",
          "name": "accelerations",
          "description": "40 timesteps (0.1 second per timestep) * 12 movement features (3x gravity, 3x acceleration, 3x euler angle, 3x rotation rate)"
        },
        {
          "type": "MultiArray (Double 32)",
          "name": "lstm_1_h_in"
        },
        {
          "type": "MultiArray (Double 32)",
          "name": "lstm_1_c_in"
        },
        {
          "type": "MultiArray (Double 32)",
          "name": "lstm_2_h_in"
        },
        {
          "type": "MultiArray (Double 32)",
          "name": "lstm_2_c_in"
        }
      ],
      "size": "84.0 KB",
      "primary_output": "scores",
      "samples": [
        {
          "input": {
            "lstm_1_h_in": {},
            "lstm_2_h_in": {},
            "accelerations": {
              "content": "squat_sample.png",
              "type": "image"
            },
            "lstm_2_c_in": {},
            "lstm_1_c_in": {}
          },
          "output": {
            "lstm_2_h_out": {},
            "lstm_1_h_out": {},
            "lstm_1_c_out": {},
            "lstm_2_c_out": {},
            "scores": {
              "content": "squat",
              "type": "text"
            }
          }
        },
        {
          "input": {
            "lstm_1_h_in": {},
            "lstm_2_h_in": {},
            "accelerations": {
              "content": "situp_sample.png",
              "type": "image"
            },
            "lstm_2_c_in": {},
            "lstm_1_c_in": {}
          },
          "output": {
            "lstm_2_h_out": {},
            "lstm_1_h_out": {},
            "lstm_1_c_out": {},
            "lstm_2_c_out": {},
            "scores": {
              "content": "situp",
              "type": "text"
            }
          }
        }
      ],
      "primary_input": "accelerations"
    }
  ]
}